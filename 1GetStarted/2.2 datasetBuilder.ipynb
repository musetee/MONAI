{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目录\n",
    "\n",
    "1. torch.utils.data.Dataset\n",
    "\n",
    "2. torch.utils.data.DataLoader\n",
    "\n",
    "3. transforms\n",
    "\n",
    "    3.1 pytorch官方API\n",
    "        \n",
    "        3.1.1 transforms.Compose\n",
    "\n",
    "        3.1.2 transforms.ToTensor\n",
    "\n",
    "    3.2 自定义transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在pytorch中，提供了一种十分方便的数据读取机制，即使用torch.utils.data.Dataset与torch.utils.data.DataLoader组合得到数据迭代器。在每次训练时，利用这个迭代器输出每一个batch数据，并能在输出时对数据进行相应的预处理或数据增强等操作。\n",
    "\n",
    "# torch.utils.data.Dataset\n",
    "\n",
    "torch.utils.data.Dataset是代表自定义数据集方法的类，用户可以通过继承该类来自定义自己的数据集类，\n",
    "\n",
    "定义数据集结构：\n",
    "\n",
    "__init__()\n",
    "\n",
    "在继承时要求用户重载__len__()和__getitem__():\n",
    "\n",
    "__len__(self)：返回的是数据集的大小。我们构建的数据集是一个对象，而数据集不像序列类型（列表、元组、字符串）那样可以直接用len()来获取序列的长度，魔法方法__len__()的目的就是方便像序列那样直接获取对象的长度。如果A是一个类，a是类A的实例化对象，当A中定义了魔法方法__len__()，len(a)则返回对象的大小。\n",
    "\n",
    "__getitem__(self, ...)：实现索引数据集中的某一个数据。我们知道，序列可以通过索引的方法获取序列中的任意元素，__getitem__()则实现了能够通过索引的方法获取对象中的任意元素。此外，我们可以在__getitem__()中实现数据预处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 示例1\n",
    "该例子中，dataset是组合data和target，对应起来，当然可以改变这个数据形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_tensor: tensor([[-0.7146, -0.5503, -0.6698],\n",
      "        [-0.2480,  0.7401,  0.3933],\n",
      "        [ 0.4851,  0.8629,  0.6338],\n",
      "        [-0.5416,  0.3569, -0.0729]])\n",
      "target_tensor: tensor([0.5103, 0.6953, 0.4721, 0.8254])\n",
      "tensor_dataset[1]: (tensor([-0.2480,  0.7401,  0.3933]), tensor(0.6953))\n",
      "len: 4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class TensorDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    TensorDataset继承Dataset, 重载了__init__(), __getitem__(), __len__()\n",
    "    实现将一组Tensor数据对封装成Tensor数据集\n",
    "    能够通过index得到数据集的数据，能够通过len，得到数据集大小\n",
    "    \"\"\"\n",
    "    def __init__(self, data_tensor, target_tensor):\n",
    "        self.data_tensor = data_tensor\n",
    "        self.target_tensor = target_tensor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data_tensor[index], self.target_tensor[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_tensor.size(0)\n",
    "\n",
    "# 生成数据\n",
    "data_tensor = torch.randn(4, 3)\n",
    "target_tensor = torch.rand(4)\n",
    "print('data_tensor:', data_tensor)\n",
    "print('target_tensor:', target_tensor)\n",
    "# 将数据封装成Dataset\n",
    "# 调用init\n",
    "tensor_dataset = TensorDataset(data_tensor, target_tensor)\n",
    "\n",
    "# 可使用索引调用数据\n",
    "# 调用getitem\n",
    "print('tensor_dataset[1]:',tensor_dataset[1])\n",
    "# 输出：(tensor([-1.0351, -0.1004,  0.9168]), tensor(0.4977))\n",
    "\n",
    "# 获取数据集大小\n",
    "# 调用len\n",
    "print('len:',len(tensor_dataset))\n",
    "# 输出：4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 示例2\n",
    "该例子加载图片文件夹作为dataset，还可以加载数据集的同时做transforms\n",
    "\n",
    "**param**\n",
    "\n",
    "data_dir: 数据集所在路径\n",
    "\n",
    "transform: 数据预处理\n",
    "\n",
    "注意data_info加载了自己的函数：self.get_img_info(data_dir)，他的功能是读取train_dataset.txt，该文件存储了每个图片的路径以及图片的label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class PatchDataset(Dataset):\n",
    "    def __init__(self, data_dir, transforms=None):\n",
    "        self.data_info = self.get_img_info(data_dir)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        path_img, label = self.data_info[item]\n",
    "        image = Image.open(path_img).convert('RGB')\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_img_info(data_dir):\n",
    "        path_dir = os.path.join(data_dir, 'train_dataset.txt')\n",
    "        data_info = []\n",
    "        with open(path_dir) as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                data_info.append(line.strip('\\n').split(' '))\n",
    "        return data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagedataPath='C:\\\\Users\\\\56991\\\\OneDrive\\\\PhD\\\\data\\\\MedNIST\\\\AbdomenCT'\n",
    "imagedata=PatchDataset(imagedataPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.utils.data.DataLoader\n",
    "\n",
    "## 作用：\n",
    "\n",
    "DataLoader将Dataset对象或自定义数据类的对象封装成一个迭代器；\n",
    "\n",
    "这个迭代器可以迭代输出Dataset的内容；\n",
    "\n",
    "同时可以实现多进程、shuffle、不同采样策略，数据校对等等处理过程。\n",
    "\n",
    "## __init__()中的几个重要的输入：\n",
    "dataset：这个就是pytorch已有的数据读取接口（比如torchvision.datasets.ImageFolder）或者自定义的数据接口的输出，该输出要么是torch.utils.data.Dataset类的对象，要么是继承自torch.utils.data.Dataset类的自定义类的对象。\n",
    "\n",
    "batch_size：根据具体情况设置即可。\n",
    "\n",
    "shuffle：随机打乱顺序，一般在训练数据中会采用。\n",
    "\n",
    "collate_fn：是用来处理不同情况下的输入dataset的封装，一般采用默认即可，除非你自定义的数据读取输出非常少见。\n",
    "\n",
    "batch_sampler：从注释可以看出，其和batch_size、shuffle等参数是互斥的，一般采用默认。\n",
    "\n",
    "sampler：从代码可以看出，其和shuffle是互斥的，一般默认即可。\n",
    "\n",
    "num_workers：从注释可以看出这个参数必须大于等于0，0的话表示数据导入在主进程中进行，其他大于0的数表示通过多个进程来导入数据，可以加快数据导入速度。\n",
    "\n",
    "pin_memory：注释写得很清楚了： pin_memory (bool, optional): If True, the data loader will copy tensors into CUDA pinned memory before returning them. 也就是一个数据拷贝的问题。\n",
    "\n",
    "timeout：是用来设置数据读取的超时时间的，但超过这个时间还没读取到数据的话就会报错。\n",
    "\n",
    "## 代码示例（接示例1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_tensor: tensor([[-0.7146, -0.5503, -0.6698],\n",
      "        [-0.2480,  0.7401,  0.3933],\n",
      "        [ 0.4851,  0.8629,  0.6338],\n",
      "        [-0.5416,  0.3569, -0.0729]])\n",
      "target_tensor: tensor([0.5103, 0.6953, 0.4721, 0.8254])\n",
      "dataloader:\n",
      "tensor([[-0.7146, -0.5503, -0.6698],\n",
      "        [-0.2480,  0.7401,  0.3933]]) tensor([0.5103, 0.6953])\n",
      "tensor([[-0.5416,  0.3569, -0.0729],\n",
      "        [ 0.4851,  0.8629,  0.6338]]) tensor([0.8254, 0.4721])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "tensor_dataloader = DataLoader(tensor_dataset,   # 封装的对象\n",
    "                               batch_size=2,     # 输出的batch size\n",
    "                               shuffle=True,     # 随机输出\n",
    "                               num_workers=0)    # 只有1个进程，这个不要乱改，改了好像会出问题\n",
    "\n",
    "# 以for循环形式输出\n",
    "print('data_tensor:', data_tensor)\n",
    "print('target_tensor:', target_tensor)\n",
    "print('dataloader:')\n",
    "for data, target in tensor_dataloader:\n",
    "    print(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transforms\n",
    "\n",
    "这个transforms和MONAI的其实很接近了，这里是详细讲解了底层代码\n",
    "\n",
    "## pytorch官方API\n",
    "transforms主要实现对数据集的预处理、数据增强、转换成tensor等一系列操作，使用以下代码可导入transforms文件。\n",
    "\n",
    "transforms主要用在Dataset类构建过程中，整个流程如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_dir, transforms=None):\n",
    "        self.data_info = self.get_img_info(data_dir)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        path_img, label = self.data_info[item]\n",
    "        image = Image.open(path_img).convert('RGB')\n",
    "        # 使用定义好的transforms，对数据进行处理\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                       transforms.RandomHorizontalFlip(0.5)])\n",
    "train_dataset = MyDataset(data_dir, train_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来介绍transforms的原理及用法。\n",
    "\n",
    "### transforms.Compose\n",
    "Compose类的作用是组合多个transforms函数，Compose类的初始化函数中需要传入一个含有多种transform方法的列表，随后将图像逐一通过这些transform方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compose:\n",
    "    \"\"\"Composes several transforms together. This transform does not support torchscript.\n",
    "    Please, see the note below.\n",
    "\n",
    "    Args:\n",
    "        transforms (list of ``Transform`` objects): list of transforms to compose.\n",
    "\n",
    "    Example:\n",
    "        >>> transforms.Compose([\n",
    "        >>>     transforms.CenterCrop(10),\n",
    "        >>>     transforms.ToTensor(),\n",
    "        >>> ])\n",
    "\n",
    "    .. note::\n",
    "        In order to script the transformations, please use ``torch.nn.Sequential`` as below.\n",
    "\n",
    "        >>> transforms = torch.nn.Sequential(\n",
    "        >>>     transforms.CenterCrop(10),\n",
    "        >>>     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "        >>> )\n",
    "        >>> scripted_transforms = torch.jit.script(transforms)\n",
    "\n",
    "        Make sure to use only scriptable transformations, i.e. that work with ``torch.Tensor``, does not require\n",
    "        `lambda` functions or ``PIL.Image``.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img):\n",
    "        for t in self.transforms:\n",
    "            img = t(img)\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "类中定义了__call__()方法，作用是可以将类实例化后得到的对象当做函数来使用，比如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "class SquareNum():\n",
    "    def __call__(self, x):\n",
    "        return x ** 2\n",
    "        \n",
    "square_num = SquareNum()\n",
    "print(square_num(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于类SquareNum实现了魔法方法__call__()，那么square_num(2)就是把对象名当做函数名来使用。\n",
    "### transforms.ToTensor\n",
    "这个类的作用是将PIL Image或numpy.ndarray转换成tensor，在转换前会将调整维度，并进行单位化：\n",
    "Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import functional as F\n",
    "class ToTensor:\n",
    "    \"\"\"Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor. This transform does not support torchscript.\n",
    "\n",
    "    Converts a PIL Image or numpy.ndarray (H x W x C) in the range\n",
    "    [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]\n",
    "    if the PIL Image belongs to one of the modes (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1)\n",
    "    or if the numpy.ndarray has dtype = np.uint8\n",
    "\n",
    "    In the other cases, tensors are returned without scaling.\n",
    "\n",
    "    .. note::\n",
    "        Because the input image is scaled to [0.0, 1.0], this transformation should not be used when\n",
    "        transforming target image masks. See the `references`_ for implementing the transforms for image masks.\n",
    "\n",
    "    .. _references: https://github.com/pytorch/vision/tree/master/references/segmentation\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, pic):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Converted image.\n",
    "        \"\"\"\n",
    "        return F.to_tensor(pic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义transforms\n",
    "对于目标检测，在对原始图像进行数据增强时，需要同时对目标的边界框坐标做相应的调整；或者我们需要构建自己的数据增强方法，这个时候我们就需要自己定义transforms。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "\n",
    "class Compose(object):\n",
    "    \"\"\"组合多个transform函数\"\"\"\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        for t in self.transforms:\n",
    "            image, target = t(image, target)\n",
    "        return image, target\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"将PIL图像转为Tensor\"\"\"\n",
    "    def __call__(self, image, target):\n",
    "        image = F.to_tensor(image)\n",
    "        # target不需要对维度进行调整或单位化\n",
    "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
    "        return image, target\n",
    "\n",
    "\n",
    "class RandomHorizontalFlip(object):\n",
    "    \"\"\"随机水平翻转图像以及bboxes\"\"\"\n",
    "    def __init__(self, prob=0.5):\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        if random.random() < self.prob:\n",
    "            height, width = image.shape[-2:]\n",
    "            image = image.flip(-1)  # 水平翻转图片\n",
    "            bbox = target[\"boxes\"]\n",
    "            # bbox: xmin, ymin, xmax, ymax\n",
    "            bbox[:, [0, 2]] = width - bbox[:, [2, 0]]  # 翻转对应bbox坐标信息\n",
    "            target[\"boxes\"] = bbox\n",
    "        return image, target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于图像分割，我们在做数据增强时同样需要自己定义transforms。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "\n",
    "def pad_if_smaller(img, size, fill=0):\n",
    "    min_size = min(img.size)\n",
    "    if min_size < size:\n",
    "        ow, oh = img.size\n",
    "        padh = size - oh if oh < size else 0\n",
    "        padw = size - ow if ow < size else 0\n",
    "        img = F.pad(img, (0, 0, padw, padh), fill=fill)\n",
    "    return img\n",
    "\n",
    "\n",
    "class Compose(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        for t in self.transforms:\n",
    "            image, target = t(image, target)\n",
    "        return image, target\n",
    "\n",
    "\n",
    "class RandomResize(object):\n",
    "    def __init__(self, min_size, max_size=None):\n",
    "        self.min_size = min_size\n",
    "        if max_size is None:\n",
    "            max_size = min_size\n",
    "        self.max_size = max_size\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        size = random.randint(self.min_size, self.max_size)\n",
    "        image = F.resize(image, size)\n",
    "        target = F.resize(target, size, interpolation=Image.NEAREST)\n",
    "        return image, target\n",
    "\n",
    "\n",
    "class RandomHorizontalFlip(object):\n",
    "    def __init__(self, flip_prob):\n",
    "        self.flip_prob = flip_prob\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        if random.random() < self.flip_prob:\n",
    "            image = F.hflip(image)\n",
    "            target = F.hflip(target)\n",
    "        return image, target\n",
    "\n",
    "\n",
    "class RandomCrop(object):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        image = pad_if_smaller(image, self.size)\n",
    "        target = pad_if_smaller(target, self.size, fill=255)\n",
    "        crop_params = T.RandomCrop.get_params(image, (self.size, self.size))\n",
    "        image = F.crop(image, *crop_params)\n",
    "        target = F.crop(target, *crop_params)\n",
    "        return image, target\n",
    "\n",
    "\n",
    "class CenterCrop(object):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        image = F.center_crop(image, self.size)\n",
    "        target = F.center_crop(target, self.size)\n",
    "        return image, target\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, image, target):\n",
    "        image = F.to_tensor(image)\n",
    "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
    "        return image, target\n",
    "\n",
    "\n",
    "class Normalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
    "        return image, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('MONAI41')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c01f883ef9e9befaa05a2a694449daf777fa23f3d50f249b4bf4fb6c581c032"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
